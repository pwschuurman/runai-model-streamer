{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stream Model From GCP Cloud Storage\n",
    "\n",
    "In this notebook we will demonstrate how to read tensors using the RunAI Model Streamer from GCP Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "* A Linux machine\n",
    "* A GCP Cloud Storage bucket\n",
    "* HMAC Credentials for a GCP Service Account that can read and write to the bucket (roles/storage.objectUser)\n",
    "\n",
    "Install python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3 runai-model-streamer runai-model-streamer-s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "Set the following variables with your credentials and bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_bucket = 'your-bucket-name'\n",
    "gcs_location = 'desired/path/in/gcs'\n",
    "\n",
    "# See https://cloud.google.com/storage/docs/authentication/hmackeys\n",
    "# Configured through https://console.cloud.google.com/storage/settings/interoperability\n",
    "gcs_hmac_access_key = 'your-access-key'\n",
    "gcs_hmac_access_secret = 'your-secret-access-key'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will set them as Cloud Storage environment varibles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = gcs_hmac_access_key\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = gcs_hmac_access_secret\n",
    "\n",
    "gcs_endpoint = 'https://storage.googleapis.com'\n",
    "os.environ['AWS_ENDPOINT_URL'] = gcs_endpoint\n",
    "\n",
    "# As of boto3 1.36.0, new integrity protections for checksum calculation are\n",
    "# applied by default. Disable these for now, to maintain compatibility.\n",
    "# See https://github.com/boto/boto3/issues/4392\n",
    "os.environ['AWS_REQUEST_CHECKSUM_CALCULATION'] = 'when_required'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by downloading an example `.safetensors` file. Feel free to use your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next thing we would do is upload the `model.safetensors` file to the Cloud Storage bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "local_file = 'model.safetensors'\n",
    "gcs_upload_location = f\"{gcs_location}/{local_file}\"\n",
    "\n",
    "gcs_client = boto3.client(\n",
    "    's3',\n",
    "    region_name='auto',\n",
    "    aws_access_key_id=gcs_hmac_access_key,\n",
    "    aws_secret_access_key=gcs_hmac_access_secret,\n",
    "    endpoint_url=gcs_endpoint\n",
    ")\n",
    "\n",
    "gcs_client.upload_file(local_file, gcs_bucket, gcs_upload_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "To load the tensors from the Cloud Storage file we need to create `SafetensorsStreamer` instance, perform the request, and start getting the tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from runai_model_streamer import SafetensorsStreamer\n",
    "\n",
    "# Replace \"gs://\" with \"s3://\"\n",
    "file_path = f\"s3://{gcs_bucket}/{gcs_upload_location}\"\n",
    "\n",
    "def heavy_workload(tensor):\n",
    "    # Perform heavy computation with the tensor\n",
    "    # The computation is occured during the reading\n",
    "    # of the rest of the tensors from the storage\n",
    "    return\n",
    "\n",
    "with SafetensorsStreamer() as streamer:\n",
    "    streamer.stream_file(file_path)\n",
    "    for name, tensor in streamer.get_tensors():\n",
    "        heavy_workload(tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
